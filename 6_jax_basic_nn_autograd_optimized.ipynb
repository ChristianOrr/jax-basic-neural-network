{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Jax (autograd optimized) NN from Scratch\n",
    "\n",
    "This notebook combines all the jax features used so far (jit, autograd and vmap). This notebook demonstrates how clean and fast Jax can become by using all its features together, whilst not losing control over the low level functionality of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax import nn\n",
    "from jax import vmap\n",
    "from jax import grad\n",
    "from keras.utils import data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the training data exists. If not, automatically download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.abspath(\"./digit-recognizer\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "train_data_path = f\"{data_dir}/train.csv\"\n",
    "train_data_url = \"https://huggingface.co/datasets/ChristianOrr/mnist/resolve/main/train.csv\"\n",
    "\n",
    "if not os.path.exists(train_data_path):\n",
    "    print(\"Downloading training data...\")\n",
    "    data_utils.get_file(train_data_path, train_data_url)\n",
    "\n",
    "data_df = pd.read_csv('./digit-recognizer/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data_df.values)\n",
    "m, n = data_df.shape\n",
    "Y = jnp.array(data_df[\"label\"])\n",
    "data_df = data_df.drop(\"label\", axis=1)\n",
    "X = jnp.array(data_df)\n",
    "\n",
    "\n",
    "X_train = X[1000:]\n",
    "X_train = X_train / 255.\n",
    "Y_train = Y[1000:]\n",
    "\n",
    "X_val = X[:1000]\n",
    "X_val = X_val / 255.\n",
    "Y_val = Y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our NN will have a simple two-layer architecture. Input layer $A^{[0]}$ will have 784 units corresponding to the 784 pixels in each 28x28 input image. A hidden layer $A^{[1]}$ will have 10 units with ReLU activation, and finally our output layer $A^{[2]}$ will have 10 units corresponding to the ten digit classes with softmax activation.\n",
    "\n",
    "\n",
    "**Forward propagation**\n",
    "\n",
    "Input Layer:    \n",
    "$$X = A^{[0]}$$\n",
    "\n",
    "First Hidden Layer:\n",
    "$$Z^{[1]} = W^{[1]} X + b^{[1]}$$\n",
    "$$A^{[1]} = g_{\\text{ReLU}}(Z^{[1]})$$\n",
    "\n",
    "Second Hidden Layer:\n",
    "$$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$$\n",
    "$$A^{[2]} = g_{\\text{softmax}}(Z^{[2]})$$\n",
    "\n",
    "**Backward propagation**\n",
    "\n",
    "Loss Function (Categorical Cross Entropy):  \n",
    "$$L(y, a^{[2]}) = -\\sum_{j = 1}^{C}y_{j} \\cdot\\ log(a^{[2]})$$ \n",
    "C is the number of classes, which is 10 in this case. \n",
    "\n",
    "Cost Function:\n",
    "$$J(W, b) = -\\frac{1}{m} \\sum_{i = 1}^{m} L(y^{i}, a^{[2](i)})$$ \n",
    "$$J(W, b) = -\\frac{1}{m} \\sum_{i = 1}^{m} \\sum_{j = 1}^{C}y^{i}_{j}\\cdot\\log(a^{[2](i)})$$ \n",
    "The cost function is the average of the losses over all the samples.\n",
    "\n",
    "Derivatives:    \n",
    "For detailed derivation of $dZ^{[2]}$ see: [derivation-of-categorical-cross-entropy-loss](https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1)    \n",
    "For more details on the rest of the derivations see: [backpropagation-intuition](https://www.youtube.com/watch?v=yXcQ4B-YSjQ&list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0&index=34&ab_channel=DeepLearningAI)\n",
    "$$dZ^{[2]} = A^{[2]} - Y$$\n",
    "$$dW^{[2]} = \\frac{1}{m} dZ^{[2]} A^{[1]T}$$\n",
    "$$dB^{[2]} = \\frac{1}{m} \\sum_{i = 1}^{m} {dZ^{[2]}}$$\n",
    "$$dZ^{[1]} = W^{[2]T} dZ^{[2]} .* g^{[1]\\prime} (z^{[1]})$$\n",
    "$$dW^{[1]} = \\frac{1}{m} dZ^{[1]} A^{[0]T}$$\n",
    "$$dB^{[1]} = \\frac{1}{m} \\sum_{i = 1}^{m} {dZ^{[1]}}$$\n",
    "\n",
    "**Gradient Descent (parameter updates)**\n",
    "\n",
    "$$W^{[2]} := W^{[2]} - \\alpha dW^{[2]}$$\n",
    "$$b^{[2]} := b^{[2]} - \\alpha db^{[2]}$$\n",
    "$$W^{[1]} := W^{[1]} - \\alpha dW^{[1]}$$\n",
    "$$b^{[1]} := b^{[1]} - \\alpha db^{[1]}$$\n",
    "\n",
    "**Vars and shapes**\n",
    "\n",
    "Forward prop\n",
    "\n",
    "- $A^{[0]} = X$: 784 x m\n",
    "- $Z^{[1]} \\sim A^{[1]}$: 10 x m\n",
    "- $W^{[1]}$: 10 x 784 (as $W^{[1]} A^{[0]} \\sim Z^{[1]}$)\n",
    "- $B^{[1]}$: 10 x 1\n",
    "- $Z^{[2]} \\sim A^{[2]}$: 10 x m\n",
    "- $W^{[1]}$: 10 x 10 (as $W^{[2]} A^{[1]} \\sim Z^{[2]}$)\n",
    "- $B^{[2]}$: 10 x 1\n",
    "\n",
    "Backprop\n",
    "\n",
    "- $dZ^{[2]}$: 10 x m ($~A^{[2]}$)\n",
    "- $dW^{[2]}$: 10 x 10\n",
    "- $dB^{[2]}$: 10 x 1\n",
    "- $dZ^{[1]}$: 10 x m ($~A^{[1]}$)\n",
    "- $dW^{[1]}$: 10 x 10\n",
    "- $dB^{[1]}$: 10 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def init_params():\n",
    "    key = random.PRNGKey(42)\n",
    "    key, *subkey = random.split(key, 5)\n",
    "    W1 = random.uniform(subkey[0], (10, 784), jnp.float32, -0.5, 0.5)\n",
    "    b1 = random.uniform(subkey[1], (10,), jnp.float32, -0.5, 0.5)\n",
    "    W2 = random.uniform(subkey[2], (10, 10), jnp.float32, -0.5, 0.5)\n",
    "    b2 = random.uniform(subkey[3], (10,), jnp.float32, -0.5, 0.5)\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "@jax.jit\n",
    "def ReLU(Z):\n",
    "    return jnp.maximum(Z, 0)\n",
    "\n",
    "@jax.jit\n",
    "def softmax(Z):\n",
    "    A = jnp.exp(Z) / sum(jnp.exp(Z))\n",
    "    return A   \n",
    "\n",
    "@jax.jit\n",
    "def forward(W1, b1, W2, b2, x):\n",
    "    # single example forward pass\n",
    "    z1 = W1.dot(x) + b1\n",
    "    a1 = ReLU(z1)\n",
    "    z2 = W2.dot(a1) + b2\n",
    "    a2 = softmax(z2)\n",
    "    return a2\n",
    "\n",
    "batched_forward = jax.jit(vmap(forward, in_axes=(None, None, None, None, 0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the one_hot function needed to have a static argument since the value of k was used in the function. All the rest could be jitted exactly as they were. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=['k'])\n",
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "\n",
    "@jax.jit\n",
    "def loss_fn(W1, b1, W2, b2, X, Y):\n",
    "    A2 = batched_forward(W1, b1, W2, b2, X)\n",
    "    one_hot_Y = one_hot(Y, 10)\n",
    "    loss = -jnp.sum(one_hot_Y * jnp.log(A2)) / m\n",
    "    return loss\n",
    "\n",
    "@jax.jit\n",
    "def update_params(W1, b1, W2, b2, alpha, X, Y):\n",
    "    dW1, db1, dW2, db2 = grad(loss_fn, argnums=(0, 1, 2, 3))(W1, b1, W2, b2, X, Y)\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1    \n",
    "    W2 = W2 - alpha * dW2  \n",
    "    b2 = b2 - alpha * db2    \n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def get_predictions(A2):\n",
    "    return jnp.argmax(A2, axis=1)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return jnp.mean(predictions == Y)\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, alpha, X, Y)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            A2 = batched_forward(W1, b1, W2, b2, X)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[6 3 8 ... 6 6 6] [2 6 8 ... 4 2 3]\n",
      "0.12307317\n",
      "Iteration:  10\n",
      "[1 6 8 ... 6 3 0] [2 6 8 ... 4 2 3]\n",
      "0.25336584\n",
      "Iteration:  20\n",
      "[1 6 8 ... 1 3 0] [2 6 8 ... 4 2 3]\n",
      "0.34129268\n",
      "Iteration:  30\n",
      "[1 1 8 ... 1 3 0] [2 6 8 ... 4 2 3]\n",
      "0.39712194\n",
      "Iteration:  40\n",
      "[2 1 8 ... 1 3 0] [2 6 8 ... 4 2 3]\n",
      "0.44929266\n",
      "Iteration:  50\n",
      "[3 1 8 ... 4 3 0] [2 6 8 ... 4 2 3]\n",
      "0.5004634\n",
      "Iteration:  60\n",
      "[3 1 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.5437317\n",
      "Iteration:  70\n",
      "[3 1 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.5816829\n",
      "Iteration:  80\n",
      "[3 1 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.60802436\n",
      "Iteration:  90\n",
      "[3 1 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.62985367\n",
      "Iteration:  100\n",
      "[3 1 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.64982927\n",
      "Iteration:  110\n",
      "[3 1 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.6669024\n",
      "Iteration:  120\n",
      "[2 1 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.68109757\n",
      "Iteration:  130\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.69382924\n",
      "Iteration:  140\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.7034878\n",
      "Iteration:  150\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.7142439\n",
      "Iteration:  160\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.7237073\n",
      "Iteration:  170\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.73204875\n",
      "Iteration:  180\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.7387073\n",
      "Iteration:  190\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.7459512\n",
      "Iteration:  200\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.7522439\n",
      "Iteration:  210\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.758439\n",
      "Iteration:  220\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.76421946\n",
      "Iteration:  230\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.77075607\n",
      "Iteration:  240\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.7751951\n",
      "Iteration:  250\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.7801219\n",
      "Iteration:  260\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.7842195\n",
      "Iteration:  270\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.78860974\n",
      "Iteration:  280\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.79278046\n",
      "Iteration:  290\n",
      "[2 2 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.79663414\n",
      "Iteration:  300\n",
      "[2 6 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.8001951\n",
      "Iteration:  310\n",
      "[2 6 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.8039268\n",
      "Iteration:  320\n",
      "[2 6 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.807\n",
      "Iteration:  330\n",
      "[2 6 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.8096829\n",
      "Iteration:  340\n",
      "[2 6 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.81185365\n",
      "Iteration:  350\n",
      "[2 6 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.81448776\n",
      "Iteration:  360\n",
      "[2 6 8 ... 4 3 3] [2 6 8 ... 4 2 3]\n",
      "0.8169756\n",
      "Iteration:  370\n",
      "[2 6 8 ... 4 2 3] [2 6 8 ... 4 2 3]\n",
      "0.81939024\n",
      "Iteration:  380\n",
      "[2 6 8 ... 4 2 3] [2 6 8 ... 4 2 3]\n",
      "0.821439\n",
      "Iteration:  390\n",
      "[2 6 8 ... 4 2 3] [2 6 8 ... 4 2 3]\n",
      "0.82382923\n",
      "Iteration:  400\n",
      "[2 6 8 ... 4 2 3] [2 6 8 ... 4 2 3]\n",
      "0.8261463\n",
      "Iteration:  410\n",
      "[2 6 8 ... 4 2 3] [2 6 8 ... 4 2 3]\n",
      "0.8285853\n",
      "Iteration:  420\n",
      "[2 6 8 ... 4 2 3] [2 6 8 ... 4 2 3]\n",
      "0.831\n",
      "Iteration:  430\n",
      "[2 6 8 ... 4 2 3] [2 6 8 ... 4 2 3]\n",
      "0.8326585\n",
      "Iteration:  440\n",
      "[2 6 8 ... 4 2 3] [2 6 8 ... 4 2 3]\n",
      "0.83478045\n",
      "Iteration:  450\n",
      "[2 6 8 ... 4 2 3] [2 6 8 ... 4 2 3]\n",
      "0.8360488\n",
      "Iteration:  460\n",
      "[2 6 8 ... 4 2 3] [2 6 8 ... 4 2 3]\n",
      "0.83807313\n",
      "Iteration:  470\n",
      "[2 6 8 ... 4 2 3] [2 6 8 ... 4 2 3]\n",
      "0.839878\n",
      "Iteration:  480\n",
      "[2 6 8 ... 4 2 3] [2 6 8 ... 4 2 3]\n",
      "0.8412927\n",
      "Iteration:  490\n",
      "[2 6 8 ... 4 2 3] [2 6 8 ... 4 2 3]\n",
      "0.8430731\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    A2 = batched_forward(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[None, index]\n",
    "    prediction = make_predictions(X_train[None, index], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [2]\n",
      "Label:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [6]\n",
      "Label:  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [8]\n",
      "Label:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [6]\n",
      "Label:  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(0, W1, b1, W2, b2)\n",
    "test_prediction(1, W1, b1, W2, b2)\n",
    "test_prediction(2, W1, b1, W2, b2)\n",
    "test_prediction(3, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 6 9 9 2 6 7 2 6 6 6 8 5 4 7 9 7 1 0 6 2 3 4 2 8 0 7 1 7 9 8 9 0 7 1 7\n",
      " 8 6 7 2 8 2 6 8 5 1 0 0 2 6 7 2 2 3 4 2 3 8 3 8 2 0 7 5 6 0 4 1 7 1 8 1 1\n",
      " 1 7 5 3 3 2 6 4 1 9 6 4 1 0 5 9 8 6 4 8 1 5 2 4 2 1 7 4 6 1 6 6 3 6 3 4 1\n",
      " 3 0 7 6 7 4 7 1 4 4 6 2 9 2 9 2 8 9 3 6 3 2 7 6 9 5 0 1 8 6 1 6 1 7 8 0 0\n",
      " 3 7 0 3 9 6 1 1 3 1 1 6 1 5 2 6 8 0 3 2 2 8 8 6 6 3 8 8 1 9 6 7 7 9 0 6 1\n",
      " 0 6 1 9 0 3 9 1 6 3 1 3 0 0 8 8 5 8 0 7 3 6 3 9 3 4 4 4 4 5 3 4 5 1 8 1 5\n",
      " 8 2 8 6 0 8 1 0 0 4 4 5 0 6 4 4 1 0 8 8 1 8 3 3 9 9 1 7 8 4 1 1 2 0 3 6 2\n",
      " 8 2 9 2 5 1 1 2 7 2 1 9 0 7 8 7 3 6 7 2 4 4 7 6 0 3 0 9 2 5 2 6 8 4 6 1 2\n",
      " 1 0 5 1 4 4 9 0 5 5 1 8 3 3 1 4 1 0 0 4 1 8 8 9 0 4 5 5 7 9 3 7 2 6 4 5 4\n",
      " 5 1 8 6 3 6 0 1 3 3 0 2 2 7 5 8 9 9 0 4 5 7 3 8 1 0 4 9 9 1 9 2 3 0 1 1 0\n",
      " 4 5 0 3 1 1 5 2 3 9 4 3 9 7 4 3 4 1 7 1 1 1 1 6 3 1 6 1 3 2 4 4 2 9 6 2 6\n",
      " 3 3 6 2 0 8 9 2 3 4 0 9 1 4 9 3 7 1 9 3 6 8 4 1 1 3 2 9 7 4 4 7 0 7 4 6 3\n",
      " 1 7 7 3 3 6 0 1 8 7 1 6 3 4 2 7 7 3 3 5 2 0 4 0 0 6 9 9 3 6 7 9 4 6 2 8 1\n",
      " 3 1 1 0 3 5 9 7 6 9 2 7 6 5 7 1 1 5 6 0 7 3 9 6 8 5 1 0 5 8 6 8 8 1 5 2 7\n",
      " 7 6 1 4 8 7 6 7 9 2 8 9 7 1 3 0 0 9 3 3 8 7 1 6 4 7 1 4 1 9 9 8 2 0 0 0 4\n",
      " 0 1 9 1 3 4 8 7 3 5 8 1 6 9 5 9 5 7 4 2 4 3 0 7 7 6 1 6 4 9 0 0 3 2 7 4 5\n",
      " 3 9 9 0 4 0 3 7 9 5 4 4 5 1 0 4 4 6 2 9 7 4 6 6 6 7 6 9 4 4 0 0 5 8 4 7 0\n",
      " 0 7 8 8 4 3 2 6 4 1 5 1 6 3 6 7 3 2 1 2 9 8 4 9 0 4 7 8 4 2 7 0 6 3 3 3 7\n",
      " 3 2 3 8 4 8 8 2 9 9 4 4 9 0 1 0 6 8 0 7 8 3 9 3 4 4 7 4 1 6 6 6 5 0 1 5 0\n",
      " 8 1 9 3 8 7 9 3 7 4 4 6 3 6 1 0 7 1 6 1 5 5 0 7 7 0 7 1 1 0 6 1 9 0 3 4 5\n",
      " 9 0 9 0 4 1 1 8 8 8 9 0 7 4 7 0 6 0 6 7 5 3 1 0 4 5 1 1 3 0 3 9 9 6 9 7 7\n",
      " 3 1 7 2 9 8 7 8 7 1 8 6 6 9 8 3 0 1 0 0 4 9 1 7 4 5 2 8 0 3 8 0 1 7 4 6 2\n",
      " 7 2 6 8 5 0 3 7 5 3 6 3 8 5 9 0 4 1 7 6 0 7 0 1 0 4 6 4 6 2 3 3 3 7 5 3 5\n",
      " 1 7 7 9 2 9 7 1 6 3 4 7 2 6 9 2 8 3 8 8 4 0 3 2 5 0 4 4 3 1 5 3 2 6 9 3 9\n",
      " 9 6 7 8 8 8 0 3 4 8 1 9 4 5 2 6 1 8 7 7 8 0 1 2 7 2 7 4 7 1 3 5 8 1 9 1 9\n",
      " 4 8 8 9 0 9 4 0 0 4 8 3 5 3 5 7 5 7 9 2 6 5 7 4 6 6 0 8 0 9 9 8 1 1 0 7 4\n",
      " 4 9 5 3 4 4 3 8 5 0 9 6 5 4 7 8 8 5 3 7 2 3 9 1 8 5 2 0 4 8 6 1 2 5 5 9 8\n",
      " 6] [5 4 6 9 3 2 5 7 7 6 6 6 8 5 4 7 9 7 1 0 6 2 3 4 2 8 0 7 1 7 9 8 9 0 7 1 7\n",
      " 0 6 7 2 8 7 6 8 8 1 0 0 2 6 7 2 6 3 4 2 3 8 3 8 2 0 7 5 6 0 6 1 7 1 8 1 1\n",
      " 1 7 5 3 2 2 6 4 1 8 6 4 1 0 5 9 2 6 6 5 1 5 2 4 2 1 7 4 6 1 6 6 3 6 3 4 1\n",
      " 3 0 7 6 7 4 3 1 4 4 6 2 9 2 9 2 8 9 3 6 3 2 7 6 9 8 0 6 8 6 2 6 1 7 1 0 0\n",
      " 3 7 0 3 9 6 1 1 3 1 5 6 5 5 7 6 5 0 2 2 5 8 3 6 5 3 8 8 1 9 6 7 7 9 0 6 1\n",
      " 0 6 1 3 0 3 9 1 6 3 1 3 0 0 8 8 0 8 0 7 3 6 3 9 3 4 4 4 7 5 3 4 5 1 8 1 5\n",
      " 8 3 8 6 0 8 1 0 0 4 4 5 0 6 4 4 1 0 8 8 1 8 3 3 7 9 1 7 8 4 1 1 2 0 2 6 8\n",
      " 8 2 9 2 5 1 1 2 7 2 1 9 0 7 5 7 3 6 7 2 4 4 7 6 0 3 5 4 2 5 2 6 8 9 6 1 2\n",
      " 1 0 5 1 4 4 9 0 5 5 1 8 3 3 2 4 1 0 0 7 1 8 2 4 0 4 5 5 7 4 3 7 2 6 4 8 9\n",
      " 5 1 8 6 3 6 0 1 3 3 0 2 2 7 0 8 9 9 0 4 5 7 3 8 1 0 4 9 9 1 9 0 3 0 1 1 2\n",
      " 4 5 0 3 1 1 5 3 3 9 4 3 9 7 4 3 4 1 7 1 1 1 1 6 3 1 6 1 3 2 4 4 2 9 6 2 6\n",
      " 3 3 6 2 0 8 9 2 3 4 0 9 1 4 4 3 7 1 4 3 6 8 9 1 1 3 6 9 7 4 4 5 0 7 4 6 3\n",
      " 1 7 7 3 3 6 0 1 8 9 1 6 3 4 2 7 7 3 3 5 7 0 4 0 0 6 9 5 5 6 7 7 4 6 2 9 1\n",
      " 5 1 1 0 3 5 9 7 6 9 2 7 6 5 7 1 1 5 2 0 7 3 9 6 8 5 1 0 5 5 2 8 8 1 5 3 7\n",
      " 7 6 1 4 8 7 6 7 9 2 8 9 9 1 3 0 0 9 3 3 8 3 1 6 4 7 1 2 1 9 9 8 2 0 0 0 4\n",
      " 0 1 9 1 3 4 8 9 3 5 8 1 6 9 5 9 5 7 4 2 4 3 0 7 7 6 1 4 4 9 0 0 3 2 7 8 0\n",
      " 3 4 9 0 2 0 5 2 9 5 4 4 3 1 0 4 4 6 2 4 7 4 6 6 6 7 6 9 4 4 0 0 5 8 4 7 8\n",
      " 0 7 3 8 4 3 2 2 4 1 1 1 6 5 6 7 3 2 1 2 9 8 4 9 0 4 7 8 4 2 7 0 6 3 3 9 7\n",
      " 5 2 3 8 8 8 8 2 4 9 4 4 9 0 1 0 6 3 0 7 8 3 9 3 4 4 7 4 1 6 0 6 5 0 8 3 0\n",
      " 8 1 9 3 8 7 9 3 7 4 4 6 5 6 1 0 7 1 2 1 5 5 0 7 7 0 7 1 1 0 8 9 9 6 3 4 5\n",
      " 9 0 9 0 4 1 3 8 8 8 9 0 7 4 7 0 6 0 6 9 5 3 1 0 4 5 8 1 3 0 3 9 9 6 4 7 7\n",
      " 3 1 7 3 9 8 7 8 7 1 8 6 6 9 8 3 0 9 0 0 2 9 7 7 4 5 2 8 0 3 5 6 1 5 4 6 2\n",
      " 7 2 6 8 5 0 3 7 5 3 6 3 8 5 9 0 4 1 7 6 0 7 8 1 0 4 6 4 6 2 3 3 8 7 5 8 5\n",
      " 1 7 7 9 2 3 7 1 6 3 9 7 2 6 9 2 5 3 8 8 4 0 5 2 5 0 4 4 3 1 5 3 2 8 9 3 4\n",
      " 9 5 7 8 8 8 0 3 4 3 1 9 4 5 2 6 1 8 7 7 8 0 8 8 8 2 7 4 8 1 5 5 8 1 9 1 9\n",
      " 4 8 8 9 8 9 4 0 0 4 8 3 5 3 8 7 5 7 9 5 6 3 7 4 6 6 0 5 0 9 9 8 1 7 0 7 4\n",
      " 4 9 5 3 4 5 3 8 5 0 9 6 5 4 7 8 8 5 3 9 2 3 9 1 8 5 2 0 9 8 1 1 2 5 5 9 8\n",
      " 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.86800003, dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predictions = make_predictions(X_val, W1, b1, W2, b2)\n",
    "get_accuracy(val_predictions, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No loss in accuracy during training or inferencing compared to all other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_X_input = X_val.copy()\n",
    "\n",
    "for i in range(6):\n",
    "    large_X_input = jnp.concatenate((large_X_input, large_X_input), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64000, 784)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_X_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.36 ms ± 1.22 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit batched_forward(W1, b1, W2, b2, large_X_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Jit enables an easy way to optimize your code. The training was significantly faster than all other methods, including the explicit jitted derivatives version (7.1s vs 1.3s). The standard autograd training was slower than the standard explicit derivatives version (14.7s vs 7.1s). So it was surprising to see how autograd combined with jit is faster than any other method. This provides an even bigger reason to use all Jax's tools together (jit, autograd and vmap)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('flax')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a8d1f2580cdfde5c5829808ec6fccc81a351d243fb8b1925f7928e44ccf575b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
