{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Jax (haiku optimized) NN from Scratch\n",
    "\n",
    "Haiku is a deep learning library designed for Jax. It provides a set of tools that make defining models and handling initialization and paramater updates much easier. In this notebook we show how to optimize a simple Haiku model using jax.jit to achieve optimal performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "from functools import partial\n",
    "import jax\n",
    "from jax import random\n",
    "from jax import nn\n",
    "from jax import vmap\n",
    "from jax import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('./digit-recognizer/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data_df.values)\n",
    "m, n = data_df.shape\n",
    "Y = jnp.array(data_df[\"label\"])\n",
    "data_df = data_df.drop(\"label\", axis=1)\n",
    "X = jnp.array(data_df)\n",
    "\n",
    "\n",
    "X_train = X[1000:]\n",
    "X_train = X_train / 255.\n",
    "Y_train = Y[1000:]\n",
    "\n",
    "X_val = X[:1000]\n",
    "X_val = X_val / 255.\n",
    "Y_val = Y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our NN will have a simple two-layer architecture. Input layer $A^{[0]}$ will have 784 units corresponding to the 784 pixels in each 28x28 input image. A hidden layer $A^{[1]}$ will have 10 units with ReLU activation, and finally our output layer $A^{[2]}$ will have 10 units corresponding to the ten digit classes with softmax activation.\n",
    "\n",
    "\n",
    "**Forward propagation**\n",
    "\n",
    "Input Layer:    \n",
    "$$X = A^{[0]}$$\n",
    "\n",
    "First Hidden Layer:\n",
    "$$Z^{[1]} = W^{[1]} X + b^{[1]}$$\n",
    "$$A^{[1]} = g_{\\text{ReLU}}(Z^{[1]})$$\n",
    "\n",
    "Second Hidden Layer:\n",
    "$$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$$\n",
    "$$A^{[2]} = g_{\\text{softmax}}(Z^{[2]})$$\n",
    "\n",
    "**Backward propagation**\n",
    "\n",
    "Loss Function (Categorical Cross Entropy):  \n",
    "$$L(y, a^{[2]}) = -\\sum_{j = 1}^{C}y_{j} \\cdot\\ log(a^{[2]})$$ \n",
    "C is the number of classes, which is 10 in this case. \n",
    "\n",
    "Cost Function:\n",
    "$$J(W, b) = -\\frac{1}{m} \\sum_{i = 1}^{m} L(y^{i}, a^{[2](i)})$$ \n",
    "$$J(W, b) = -\\frac{1}{m} \\sum_{i = 1}^{m} \\sum_{j = 1}^{C}y^{i}_{j}\\cdot\\log(a^{[2](i)})$$ \n",
    "The cost function is the average of the losses over all the samples.\n",
    "\n",
    "Derivatives:    \n",
    "For detailed derivation of $dZ^{[2]}$ see: [derivation-of-categorical-cross-entropy-loss](https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1)    \n",
    "For more details on the rest of the derivations see: [backpropagation-intuition](https://www.youtube.com/watch?v=yXcQ4B-YSjQ&list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0&index=34&ab_channel=DeepLearningAI)\n",
    "$$dZ^{[2]} = A^{[2]} - Y$$\n",
    "$$dW^{[2]} = \\frac{1}{m} dZ^{[2]} A^{[1]T}$$\n",
    "$$dB^{[2]} = \\frac{1}{m} \\sum_{i = 1}^{m} {dZ^{[2]}}$$\n",
    "$$dZ^{[1]} = W^{[2]T} dZ^{[2]} .* g^{[1]\\prime} (z^{[1]})$$\n",
    "$$dW^{[1]} = \\frac{1}{m} dZ^{[1]} A^{[0]T}$$\n",
    "$$dB^{[1]} = \\frac{1}{m} \\sum_{i = 1}^{m} {dZ^{[1]}}$$\n",
    "\n",
    "**Gradient Descent (parameter updates)**\n",
    "\n",
    "$$W^{[2]} := W^{[2]} - \\alpha dW^{[2]}$$\n",
    "$$b^{[2]} := b^{[2]} - \\alpha db^{[2]}$$\n",
    "$$W^{[1]} := W^{[1]} - \\alpha dW^{[1]}$$\n",
    "$$b^{[1]} := b^{[1]} - \\alpha db^{[1]}$$\n",
    "\n",
    "**Vars and shapes**\n",
    "\n",
    "Forward prop\n",
    "\n",
    "- $A^{[0]} = X$: 784 x m\n",
    "- $Z^{[1]} \\sim A^{[1]}$: 10 x m\n",
    "- $W^{[1]}$: 10 x 784 (as $W^{[1]} A^{[0]} \\sim Z^{[1]}$)\n",
    "- $B^{[1]}$: 10 x 1\n",
    "- $Z^{[2]} \\sim A^{[2]}$: 10 x m\n",
    "- $W^{[1]}$: 10 x 10 (as $W^{[2]} A^{[1]} \\sim Z^{[2]}$)\n",
    "- $B^{[2]}$: 10 x 1\n",
    "\n",
    "Backprop\n",
    "\n",
    "- $dZ^{[2]}$: 10 x m ($~A^{[2]}$)\n",
    "- $dW^{[2]}$: 10 x 10\n",
    "- $dB^{[2]}$: 10 x 1\n",
    "- $dZ^{[1]}$: 10 x m ($~A^{[1]}$)\n",
    "- $dW^{[1]}$: 10 x 10\n",
    "- $dB^{[1]}$: 10 x 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layers and activation functions can now be defined using Haiku's functions. No need to explicitly specify the weights and biases of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _forward_fn(x):\n",
    "    mlp = hk.Sequential([\n",
    "        hk.Linear(10), jax.nn.relu,\n",
    "        hk.Linear(10), jax.nn.softmax\n",
    "    ])\n",
    "    return mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Haiku model above is an object, not a pure function, which is required for Jax's. So the model is first transformed using the hk.transform method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_fn = hk.transform(_forward_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models layers shown below, are the same as used in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n",
      "Weights : (784, 10), Biases : (10,)\n",
      "\n",
      "linear_1\n",
      "Weights : (10, 10), Biases : (10,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_x = X_train[:5]\n",
    "rng_key = random.PRNGKey(64)\n",
    "\n",
    "initial_params = forward_fn.init(rng=rng_key, x=dummy_x)\n",
    "\n",
    "for layer_name, weights in initial_params.items():\n",
    "    print(layer_name)\n",
    "    print(\"Weights : {}, Biases : {}\\n\".format(initial_params[layer_name][\"w\"].shape, initial_params[layer_name][\"b\"].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can process a batch of any size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10903449 0.08148836 0.11404355 0.11746839 0.08617248 0.1121618\n",
      "  0.07521552 0.11107448 0.10700246 0.08633839]\n",
      " [0.1184034  0.0760287  0.12359262 0.10440519 0.07472834 0.09813596\n",
      "  0.06421445 0.12048039 0.12889716 0.09111377]\n",
      " [0.11008009 0.07168338 0.11888898 0.09912661 0.07042118 0.09882687\n",
      "  0.06582631 0.13413298 0.12996739 0.10104617]\n",
      " [0.11240921 0.07807808 0.11019351 0.09632948 0.08014824 0.09616168\n",
      "  0.08019723 0.12127028 0.12024726 0.10496502]\n",
      " [0.1098324  0.09535951 0.12875696 0.10512744 0.09696282 0.09774043\n",
      "  0.08459642 0.10147075 0.10227625 0.07787712]]\n"
     ]
    }
   ],
   "source": [
    "preds = forward_fn.apply(initial_params, rng_key, X_train[:5])\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward pass performed in the loss function now needs the .apply method. The explicit weights, biases and gradients have been replaced by params and grads in the update_params function. This saves a lot of code on more complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=['k'])\n",
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "\n",
    "@jax.jit\n",
    "def loss_fn(params, X, Y):\n",
    "    A2 = forward_fn.apply(params, rng_key, X)\n",
    "    one_hot_Y = one_hot(Y, 10)\n",
    "    loss = -jnp.sum(one_hot_Y * jnp.log(A2)) / m\n",
    "    return loss\n",
    "\n",
    "@jax.jit\n",
    "def update_rule(param, update):\n",
    "    return param - 0.1 * update\n",
    "\n",
    "@jax.jit\n",
    "def update_params(params, alpha, X, Y):\n",
    "    grads = grad(loss_fn, argnums=0)(params, X, Y)\n",
    "    params = jax.tree_util.tree_map(update_rule, params, grads)\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initialization function has been removed since Haiku handles the initialization using the .init method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def get_predictions(A2):\n",
    "    return jnp.argmax(A2, axis=1)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return jnp.mean(predictions == Y)\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    rng = jax.random.PRNGKey(42)\n",
    "    params = forward_fn.init(rng=rng, x=X)\n",
    "    for i in range(iterations):\n",
    "        params = update_params(params, alpha, X, Y)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            A2 = forward_fn.apply(params, rng, X)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[8 1 1 ... 8 1 8] [2 4 8 ... 5 5 4]\n",
      "0.16009755\n",
      "Iteration:  10\n",
      "[1 4 1 ... 8 8 5] [2 4 8 ... 5 5 4]\n",
      "0.3594878\n",
      "Iteration:  20\n",
      "[1 4 3 ... 8 8 4] [2 4 8 ... 5 5 4]\n",
      "0.59985363\n",
      "Iteration:  30\n",
      "[1 4 3 ... 9 0 9] [2 4 8 ... 5 5 4]\n",
      "0.6919756\n",
      "Iteration:  40\n",
      "[2 4 3 ... 9 0 4] [2 4 8 ... 5 5 4]\n",
      "0.7266829\n",
      "Iteration:  50\n",
      "[2 4 3 ... 9 6 4] [2 4 8 ... 5 5 4]\n",
      "0.7523171\n",
      "Iteration:  60\n",
      "[2 4 8 ... 9 6 4] [2 4 8 ... 5 5 4]\n",
      "0.7767073\n",
      "Iteration:  70\n",
      "[2 4 8 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.79614633\n",
      "Iteration:  80\n",
      "[2 4 8 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.8119268\n",
      "Iteration:  90\n",
      "[2 4 8 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.82387805\n",
      "Iteration:  100\n",
      "[2 4 8 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.83412194\n",
      "Iteration:  110\n",
      "[2 4 8 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.84156096\n",
      "Iteration:  120\n",
      "[2 4 8 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.8484146\n",
      "Iteration:  130\n",
      "[2 4 8 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.8546097\n",
      "Iteration:  140\n",
      "[2 4 8 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.8593658\n",
      "Iteration:  150\n",
      "[2 4 8 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.8631707\n",
      "Iteration:  160\n",
      "[2 4 8 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.86687803\n",
      "Iteration:  170\n",
      "[2 4 8 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.8700244\n",
      "Iteration:  180\n",
      "[2 4 8 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.87341464\n",
      "Iteration:  190\n",
      "[2 4 3 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.8764634\n",
      "Iteration:  200\n",
      "[2 4 3 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.87914634\n",
      "Iteration:  210\n",
      "[2 4 3 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.8821463\n",
      "Iteration:  220\n",
      "[2 4 3 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.88412195\n",
      "Iteration:  230\n",
      "[2 4 3 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.88602436\n",
      "Iteration:  240\n",
      "[2 4 3 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.8876829\n",
      "Iteration:  250\n",
      "[2 4 3 ... 5 6 4] [2 4 8 ... 5 5 4]\n",
      "0.889\n",
      "Iteration:  260\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.89053655\n",
      "Iteration:  270\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.89224386\n",
      "Iteration:  280\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.89348775\n",
      "Iteration:  290\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.8949756\n",
      "Iteration:  300\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.8962439\n",
      "Iteration:  310\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.8971219\n",
      "Iteration:  320\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.8980975\n",
      "Iteration:  330\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.89863414\n",
      "Iteration:  340\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.8996585\n",
      "Iteration:  350\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.90060973\n",
      "Iteration:  360\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.90107316\n",
      "Iteration:  370\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.90165854\n",
      "Iteration:  380\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.9025122\n",
      "Iteration:  390\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.90363413\n",
      "Iteration:  400\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.90426826\n",
      "Iteration:  410\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.90478045\n",
      "Iteration:  420\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.9052195\n",
      "Iteration:  430\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.9059268\n",
      "Iteration:  440\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.9064146\n",
      "Iteration:  450\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.9071707\n",
      "Iteration:  460\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.9078292\n",
      "Iteration:  470\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.9084146\n",
      "Iteration:  480\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.90880483\n",
      "Iteration:  490\n",
      "[2 4 3 ... 5 5 4] [2 4 8 ... 5 5 4]\n",
      "0.9091707\n"
     ]
    }
   ],
   "source": [
    "params = gradient_descent(X_train, Y_train, 0.10, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, params):\n",
    "    rng = jax.random.PRNGKey(42)\n",
    "    A2 = forward_fn.apply(params, rng, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, params):\n",
    "    current_image = X_train[None, index]\n",
    "    prediction = make_predictions(X_train[None, index], params)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [2]\n",
      "Label:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [4]\n",
      "Label:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [3]\n",
      "Label:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [7]\n",
      "Label:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAANCUlEQVR4nO3db4hd9Z3H8c9n3UQhjZh02CFJs7ZbAxIWtDpEwbC4lgZXkdgHSiMUC6GTB3WtpOAGfZCgT2Ldbl0QK1MiTZeutRC1KsVtNgT8B82MIWui0upKtBkyM+lGU/NAssZvH8xJmca5547n3HvPnXzfLxjuved7zzlfLvnknHvOuefniBCAc99fNd0AgN4g7EAShB1IgrADSRB2IIm/7uXKbHPoH+iyiPBs02tt2W1fb/u3tt+2vaXOsgB0l6ueZ7d9nqTfSfqapCOSRiVtiIg3SuZhyw50WTe27GskvR0R70TEKUk/l7S+xvIAdFGdsK+Q9PsZr48U0/6C7WHbY7bHaqwLQE1dP0AXESOSRiR244Em1dmyj0taOeP1F4ppAPpQnbCPSlpl+0u2F0r6hqRnOtMWgE6rvBsfER/bvkPSf0k6T9JjEfF6xzoD0FGVT71VWhnf2YGu68pFNQDmD8IOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEpXHZ5ck24clfSjptKSPI2KoE00B6LxaYS/8Y0T8oQPLAdBF7MYDSdQNe0j6te1XbQ/P9gbbw7bHbI/VXBeAGhwR1We2V0TEuO2/kbRb0j9HxAsl76++MgBzEhGebXqtLXtEjBePU5KekrSmzvIAdE/lsNteZHvxmeeS1kk61KnGAHRWnaPxg5Kesn1mOf8ZEc93pKtkrrnmmtL6iy++WHnZo6OjpfXNmzeX1l9++eXK60Z/qRz2iHhH0mUd7AVAF3HqDUiCsANJEHYgCcIOJEHYgSRqXUH3mVfGFXSzuuqqq0rru3fvLq0vWrSo8rpPnDhRWl++fHlp/aOPPqq8bnRHV66gAzB/EHYgCcIOJEHYgSQIO5AEYQeSIOxAEpxnnweuuOKK0nq7n7HW8fDDD5fW77333tL6yZMnW9Yuvvji0nlXrlxZWl+9enVpfXBwsGXt/vvvL513PuM8O5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXn2eWBgYKC0Pjk52bV1F7cKb+n9998vrZ8+fbpl7fzzzy+dt1194cKFldd90003lc77/PPz967onGcHkiPsQBKEHUiCsANJEHYgCcIOJEHYgSTqDNkM6KKLLmq6hZZOnTrVsjYxMdHDTvpD2y277cdsT9k+NGPaUtu7bb9VPC7pbpsA6prLbvxPJF1/1rQtkvZExCpJe4rXAPpY27BHxAuSjp81eb2kncXznZJu7mxbADqt6nf2wYg4WjyfkNTyZl+2hyUNV1wPgA6pfYAuIqLsBy4RMSJpROKHMECTqp56m7S9TJKKx6nOtQSgG6qG/RlJtxfPb5f0y860A6Bb2v6e3fbjkq6VNCBpUtJWSU9L+oWkv5X0rqRbI+Lsg3izLYvd+AouuOCC0vqWLa1Phlx44YWl8z7wwAOl9VWrVtWql7nssstK63feeWdpvd1v7ct+s/7cc8+Vzjuftfo9e9vv7BGxoUXpq7U6AtBTXC4LJEHYgSQIO5AEYQeSIOxAEtxKeo7Wrl3bsnbw4MHSeU+cONHpduaNsttBP/3006Xzrlu3rrQ+Pj5eWr/yyitb1o4dO1Y673zGraSB5Ag7kARhB5Ig7EAShB1IgrADSRB2IAluJT1HL730UtMtzEvDw63vSNbuPHo7W7duLa2fy+fSq2DLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ8Ht21LJ8+fLS+t69e1vWLrnkktJ5R0dHS+tXX311aT0rfs8OJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0nwe3bUsm3bttJ62bn0Dz74oHTezZs3V+gIrbTdstt+zPaU7UMzpm2zPW77QPF3Q3fbBFDXXHbjfyLp+lmm/zAiLi/+ftXZtgB0WtuwR8QLko73oBcAXVTnAN0dtl8rdvOXtHqT7WHbY7bHaqwLQE1Vw/4jSV+WdLmko5J+0OqNETESEUMRMVRxXQA6oFLYI2IyIk5HxCeSfixpTWfbAtBplcJue9mMl1+XdKjVewH0h7bn2W0/LulaSQO2j0jaKula25dLCkmHJW3qXoto0rPPPltav/HGGysv+5FHHimtv/LKK5WXjU9rG/aI2DDL5B1d6AVAF3G5LJAEYQeSIOxAEoQdSIKwA0lwK+nkhobKL2zct29fab3dv5+HHnqoZe3uu+8unff06dOldcyOW0kDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBLcSvoct3jx4tL6zp07ay3/ySefLK0/+OCDLWucR+8ttuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATn2c9xTzzxRGn90ksvrbX8/fv3l9YnJiZqLR+dw5YdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5LgPPs5YOPGjS1r1113Xa1l79q1q7Redl949Je2W3bbK23vtf2G7ddtf7eYvtT2bttvFY9Lut8ugKrmshv/saTvRcRqSVdL+o7t1ZK2SNoTEask7SleA+hTbcMeEUcjYn/x/ENJb0paIWm9pDP3NNop6eYu9QigAz7Td3bbX5T0FUm/kTQYEUeL0oSkwRbzDEsartEjgA6Y89F425+TtEvSXRHxx5m1mB7db9YR/iJiJCKGIqJ8BEEAXTWnsNteoOmg/ywiztxOdNL2sqK+TNJUd1oE0Alth2y2bU1/Jz8eEXfNmP6gpP+LiO22t0haGhGlY/AyZHM1AwMDpfWpqer/z7Y7tXbLLbdUXjaa0WrI5rl8Z79G0jclHbR9oJh2j6Ttkn5he6OkdyXd2oE+AXRJ27BHxEuSZv2fQtJXO9sOgG7hclkgCcIOJEHYgSQIO5AEYQeS4CeufWDBggWl9fvuu6+0XnatRLthkcuGVMa5hS07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBefY+sGbNmtL6pk2bKi/70UcfLa3v27ev8rIxv7BlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkOM/eB2677bauLXv79u1dWzbmF7bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BE2/PstldK+qmkQUkhaSQi/t32NknflnSseOs9EfGrbjV6Lnvvvfdqzb9jx46WtWPHjrWsIZe5XFTzsaTvRcR+24slvWp7d1H7YUT8a/faA9Apcxmf/aiko8XzD22/KWlFtxsD0Fmf6Tu77S9K+oqk3xST7rD9mu3HbC9pMc+w7THbY/VaBVDHnMNu+3OSdkm6KyL+KOlHkr4s6XJNb/l/MNt8ETESEUMRMVS/XQBVzSnsthdoOug/i4gnJSkiJiPidER8IunHksrvmgigUW3DbtuSdkh6MyL+bcb0ZTPe9nVJhzrfHoBOcdlwv5Jke62kFyUdlPRJMfkeSRs0vQsfkg5L2lQczCtbVvnKANQWEZ5tetuwdxJhB7qvVdi5gg5IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEr4ds/oOkd2e8Hiim9aN+7a1f+5LorapO9nZxq0JPf8/+qZXbY/16b7p+7a1f+5Lorape9cZuPJAEYQeSaDrsIw2vv0y/9tavfUn0VlVPemv0OzuA3ml6yw6gRwg7kEQjYbd9ve3f2n7b9pYmemjF9mHbB20faHp8umIMvSnbh2ZMW2p7t+23isdZx9hrqLdttseLz+6A7Rsa6m2l7b2237D9uu3vFtMb/exK+urJ59bz7+y2z5P0O0lfk3RE0qikDRHxRk8bacH2YUlDEdH4BRi2/0HSSUk/jYi/L6Z9X9LxiNhe/Ee5JCL+pU962ybpZNPDeBejFS2bOcy4pJslfUsNfnYlfd2qHnxuTWzZ10h6OyLeiYhTkn4uaX0DffS9iHhB0vGzJq+XtLN4vlPT/1h6rkVvfSEijkbE/uL5h5LODDPe6GdX0ldPNBH2FZJ+P+P1EfXXeO8h6de2X7U93HQzsxicMczWhKTBJpuZRdthvHvprGHG++azqzL8eV0coPu0tRFxhaR/kvSdYne1L8X0d7B+Onc6p2G8e2WWYcb/rMnPrurw53U1EfZxSStnvP5CMa0vRMR48Tgl6Sn131DUk2dG0C0epxru58/6aRjv2YYZVx98dk0Of95E2EclrbL9JdsLJX1D0jMN9PEpthcVB05ke5Gkdeq/oaifkXR78fx2Sb9ssJe/0C/DeLcaZlwNf3aND38eET3/k3SDpo/I/6+ke5vooUVffyfpf4q/15vuTdLjmt6t+39NH9vYKOnzkvZIekvSf0ta2ke9/Yemh/Z+TdPBWtZQb2s1vYv+mqQDxd8NTX92JX315HPjclkgCQ7QAUkQdiAJwg4kQdiBJAg7kARhB5Ig7EASfwLzXyp0rG/jDAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(0, params)\n",
    "test_prediction(1, params)\n",
    "test_prediction(2, params)\n",
    "test_prediction(3, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 7 1 9 8 4 5 7 7 8 4 0 4 9 7 1 8 3 6 4 7 4 2 5 7 1 0 5 2 1 6 1 1 4 9 0 4\n",
      " 1 0 7 7 6 6 7 6 2 5 0 5 0 9 0 7 4 0 6 8 8 9 5 3 5 5 7 9 0 3 9 4 3 9 6 9 0\n",
      " 1 3 5 2 5 7 1 8 6 8 4 7 6 9 6 7 8 6 3 3 4 4 2 3 4 2 6 1 7 0 4 9 6 7 5 6 8\n",
      " 8 4 1 7 4 4 5 9 4 9 1 3 1 9 7 9 5 2 1 6 1 6 1 1 6 3 0 8 8 3 8 3 7 1 3 5 4\n",
      " 2 7 3 7 5 3 9 2 5 8 4 4 6 4 2 6 1 4 8 5 6 4 1 7 2 9 6 1 8 0 3 1 9 3 6 6 6\n",
      " 6 9 4 9 5 9 8 0 8 5 7 6 4 7 8 4 7 2 2 8 9 4 1 9 8 0 5 0 2 6 5 3 0 4 7 2 0\n",
      " 5 2 5 0 0 1 0 8 4 5 1 6 3 0 6 1 1 6 7 1 4 6 4 8 9 4 9 7 8 4 4 7 5 6 0 1 6\n",
      " 4 4 9 3 7 4 8 6 5 1 6 4 3 7 3 8 1 4 2 9 6 0 1 4 8 7 1 7 5 0 4 2 1 5 1 9 7\n",
      " 9 3 6 4 3 4 2 3 1 4 8 5 3 9 3 3 8 7 4 4 3 8 5 5 8 1 6 6 3 5 5 6 4 8 7 1 4\n",
      " 3 0 3 1 2 7 6 7 8 3 7 1 0 4 9 3 3 0 5 9 3 6 1 1 9 4 7 1 1 2 3 7 8 1 4 0 0\n",
      " 5 9 0 7 4 8 0 9 0 2 2 4 8 3 7 0 6 6 9 4 3 4 6 9 6 1 4 6 5 8 2 0 5 3 7 1 7\n",
      " 7 0 3 3 6 0 0 0 6 9 0 1 5 6 8 1 0 4 3 2 6 6 4 0 3 9 8 9 1 7 9 1 7 4 0 1 8\n",
      " 6 0 6 9 8 6 6 1 3 8 3 9 6 9 5 1 0 3 4 6 1 0 6 7 0 1 7 4 8 1 7 3 2 8 4 9 1\n",
      " 6 9 8 2 2 7 9 1 9 8 4 1 8 5 6 0 0 3 2 0 6 6 2 3 6 5 1 5 1 5 9 2 0 4 4 8 1\n",
      " 4 3 4 0 5 9 2 3 2 3 9 6 4 7 8 1 4 6 5 1 1 8 4 5 0 1 3 9 1 4 1 8 5 5 1 7 3\n",
      " 9 2 1 5 3 6 4 2 5 8 2 1 9 4 8 8 6 1 0 5 8 6 5 2 5 2 7 7 6 8 6 3 2 2 4 3 4\n",
      " 8 0 1 5 3 1 8 3 1 1 6 3 6 7 0 1 2 9 0 1 0 3 1 2 6 9 7 6 7 5 2 1 8 9 6 8 8\n",
      " 6 5 7 1 9 7 5 2 0 2 9 6 8 1 2 5 8 2 3 9 2 0 6 0 1 1 2 8 7 3 3 3 3 0 8 3 2\n",
      " 3 5 2 7 5 8 2 6 5 3 4 9 7 1 6 2 9 6 9 8 7 1 2 9 6 7 7 3 5 0 6 9 9 0 2 4 7\n",
      " 8 1 1 8 0 6 0 7 6 7 5 0 0 9 0 6 5 4 4 3 1 0 4 8 6 5 9 2 0 1 5 6 0 2 3 8 4\n",
      " 4 5 8 3 9 3 4 8 5 4 0 2 3 9 3 1 4 0 8 2 1 7 5 3 0 5 3 5 2 0 1 1 5 1 0 0 6\n",
      " 0 1 5 0 9 5 3 6 4 7 6 6 7 6 0 0 6 4 7 2 5 9 7 4 5 4 7 7 0 2 2 6 9 5 9 7 2\n",
      " 1 6 1 4 2 8 1 0 1 0 8 4 0 4 0 0 3 1 7 7 5 9 7 0 4 1 4 5 2 0 3 3 5 8 2 9 4\n",
      " 1 3 6 0 6 4 6 8 4 3 2 8 8 9 2 2 7 9 9 4 0 2 5 1 2 9 2 3 7 7 4 0 4 2 1 9 9\n",
      " 4 4 3 3 0 8 1 8 8 3 3 3 6 8 8 7 0 5 5 1 6 6 3 4 9 8 5 6 6 3 5 1 2 7 1 7 1\n",
      " 6 6 9 0 0 9 4 8 7 6 9 3 9 1 3 9 3 1 3 0 6 9 7 4 6 2 4 5 9 4 4 3 0 8 3 2 0\n",
      " 2 4 8 5 6 4 8 0 5 9 6 1 8 0 6 5 8 5 0 0 4 8 7 9 9 7 7 5 9 6 7 4 0 3 4 7 2\n",
      " 6] [6 7 1 9 8 4 5 7 7 9 4 0 4 9 7 1 8 3 6 4 7 4 2 5 9 1 0 5 7 1 6 1 1 4 9 0 4\n",
      " 1 0 7 7 6 6 7 6 2 5 0 5 0 9 0 7 4 0 6 8 8 9 5 3 5 3 7 7 0 3 9 4 5 9 6 9 0\n",
      " 1 3 1 2 5 7 1 8 6 8 9 7 6 9 6 7 8 6 3 3 4 4 2 3 4 2 6 1 7 0 4 7 6 7 5 6 8\n",
      " 8 4 1 7 4 4 5 9 4 9 1 3 1 9 7 9 5 4 1 6 1 6 1 1 6 3 0 8 8 3 8 3 7 1 3 5 4\n",
      " 2 7 3 7 5 3 9 5 5 8 2 4 6 4 2 6 1 4 8 5 6 4 1 7 2 9 6 8 8 0 3 1 9 9 6 6 6\n",
      " 6 9 4 9 5 9 8 0 8 5 7 6 9 7 8 4 7 2 2 8 5 4 1 9 8 0 5 0 2 6 5 3 0 4 7 2 0\n",
      " 5 2 3 0 0 1 0 8 4 6 1 6 8 0 6 1 1 9 9 1 4 6 4 8 9 4 9 7 8 4 4 1 5 6 0 1 6\n",
      " 4 4 9 3 7 4 8 6 5 1 6 4 3 7 3 8 6 4 2 9 8 0 1 4 8 9 1 7 5 0 4 2 1 5 1 9 7\n",
      " 9 3 6 5 3 4 2 3 1 4 8 5 3 9 3 3 8 7 4 4 3 8 5 2 8 1 6 6 3 5 5 6 4 8 7 1 4\n",
      " 3 0 3 1 2 9 6 7 8 3 7 1 0 4 9 3 3 0 5 9 3 6 1 1 9 4 7 1 1 2 2 7 8 1 4 0 0\n",
      " 5 4 0 7 4 8 0 9 0 2 2 4 8 3 7 0 6 6 9 0 3 4 6 9 6 1 4 6 5 8 2 9 5 3 7 1 7\n",
      " 7 4 5 3 6 0 0 0 6 9 0 1 5 6 8 1 0 4 3 2 6 6 6 0 3 9 8 9 1 7 9 8 7 4 0 1 8\n",
      " 6 0 6 9 8 6 6 2 3 8 3 0 6 9 9 1 0 3 4 6 1 0 6 7 0 1 7 4 0 1 7 3 2 8 4 9 1\n",
      " 6 9 3 2 2 7 8 1 3 8 4 1 8 5 6 0 0 3 2 0 6 6 2 3 6 5 9 3 1 5 9 2 0 4 4 8 1\n",
      " 4 3 4 0 5 9 2 3 2 3 9 6 4 7 4 1 4 6 8 1 1 8 2 5 0 1 3 9 1 4 1 8 5 5 1 7 3\n",
      " 9 2 1 5 3 6 4 2 5 8 2 1 9 4 8 8 5 1 8 5 8 3 7 2 9 2 7 7 6 5 6 3 7 4 4 3 4\n",
      " 8 0 1 5 3 1 8 3 1 1 6 3 6 7 0 1 2 4 0 3 0 3 1 7 6 9 7 6 7 5 2 1 8 9 6 8 8\n",
      " 5 5 7 1 9 7 5 2 0 2 9 6 8 1 7 5 8 2 3 9 2 0 6 0 1 1 3 8 7 3 3 3 3 0 8 3 2\n",
      " 3 5 2 7 5 8 2 6 6 3 4 9 7 1 6 3 9 6 9 8 7 1 2 9 6 7 7 3 8 0 5 9 9 0 2 4 7\n",
      " 8 1 1 8 0 6 0 7 0 7 5 0 0 9 0 6 5 4 4 3 1 0 4 8 6 5 9 2 0 1 5 6 0 2 3 8 4\n",
      " 4 5 5 3 9 3 4 8 5 4 0 2 5 9 3 1 8 0 8 2 1 7 8 2 0 5 3 5 2 0 1 9 5 1 0 0 6\n",
      " 0 1 5 0 9 5 3 6 4 7 6 6 7 6 0 0 6 4 7 2 5 9 7 4 5 5 7 7 0 2 2 5 9 5 7 7 2\n",
      " 1 6 1 4 2 8 1 0 1 0 8 4 0 4 0 0 3 1 7 7 5 9 7 0 4 1 4 8 2 0 3 3 5 8 2 9 4\n",
      " 1 3 8 0 6 4 6 8 4 3 2 8 8 9 2 2 7 9 9 5 0 2 5 1 2 9 2 2 7 7 4 0 4 2 1 9 5\n",
      " 4 4 3 3 0 8 1 8 8 3 3 3 6 8 8 7 0 5 5 1 6 6 3 4 9 5 5 6 2 3 5 1 2 7 1 7 1\n",
      " 6 6 9 0 0 9 4 8 7 6 9 3 9 1 1 9 3 1 3 0 6 4 7 4 6 2 4 6 9 4 4 3 0 8 3 2 0\n",
      " 2 4 8 5 6 4 8 0 5 4 6 1 8 0 6 5 8 5 0 0 4 8 7 9 9 7 7 5 9 6 7 4 0 3 4 7 2\n",
      " 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.91300005, dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predictions = make_predictions(X_val, params)\n",
    "get_accuracy(val_predictions, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No loss in accuracy during training or inferencing compared to other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_X_input = X_val.copy()\n",
    "\n",
    "for i in range(6):\n",
    "    large_X_input = jnp.concatenate((large_X_input, large_X_input), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64000, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_X_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.38 ms ± 729 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "forward_opt = jax.jit(forward_fn.apply)\n",
    "%timeit forward_opt(params, rng, large_X_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Training time for Haiku optimized vs autograd optimized was the same (1.3s vs 1.3s). Inferencing time was also the same (1.36s vs 1.38s), showing that no performance was lost by using Haiku."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('jax0.3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b55b4f1ed0ab49d1b0af7b4581ff82338a5e4e950fefc3b23f0187ed730cfd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
